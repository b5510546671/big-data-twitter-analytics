{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Twitter Data\n",
    "\n",
    "## Play with Twitter Streaming API\n",
    "API stands for Application Programming Interface. It is a tool that makes the interaction with computer programs and web services easy. Many web services provides APIs to developers to interact with their services and to access data in programmatic way. For this programming experiment, we will use Twitter Streaming API to download tweets related to the 2 keywords: \"**big data**\", and \"**data analytic**\".\n",
    "### Step 1: Getting Twitter API keys\n",
    "In order to access Twitter Streaming API, we need to get 4 pieces of information from Twitter: *API key*, *API secret*, *Access token* and *Access token secret*. Follow the steps below to get all these 4 elements:\n",
    "* Create a twitter account if you do not already have one.\n",
    "* Go to https://apps.twitter.com/ and log in with your twitter credentials.\n",
    "* Click \"Create New App\"\n",
    "* Fill out the form, agree to the terms, and click \"Create your Twitter application\"\n",
    "* In the next page, click on \"API keys\" tab, and copy your \"API key\" and \"API secret\".\n",
    "* Scroll down and click \"Create my access token\", and copy your \"Access token\" and \"Access token secret\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variables that contains the user credentials to access Twitter API\n",
    "consumer_key = 'abc'\n",
    "consumer_secret = 'def'\n",
    "access_token = 'ijk'\n",
    "access_token_secret = 'lmn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Connecting to Twitter Streaming API and downloading data\n",
    "We will be using a Python library called **Tweepy** to connect to Twitter Streaming API and downloading the data.\n",
    "\n",
    "If you don't have Tweepy installed in your machine, go to this link [https://github.com/tweepy/tweepy], and follow the installation instructions.\n",
    "\n",
    "You can also run '*pip install tweepy*' in your anaconda installed directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import json\n",
    "\n",
    "#This is a basic listener that just prints received tweets to stdout.\n",
    "class MyListener(StreamListener):\n",
    "\n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            with open('tweets.json', 'a') as f:\n",
    "                f.write(data)\n",
    "                dat = json.loads(data)\n",
    "                print \"%s %s\" % (dat['created_at'], dat['text'])\n",
    "                return True\n",
    "        except BaseException as e:\n",
    "            print(\"--> Error on_data: %s\" % str(e))\n",
    "            pass\n",
    "        return True\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print status\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    #This handles Twitter authetification and the connection to Twitter Streaming API\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    twitter_stream = Stream(auth, MyListener())\n",
    "\n",
    "    #This line filter Twitter Streams to capture data by the keywords: 'python', 'javascript', 'ruby'\n",
    "    twitter_stream.filter(track=['big data', 'data analytic', 'data science', '#bigdata', '#datascience', '#dataanalytic'])\n",
    "    #twitter_stream.filter(track=['*'], languages=['th'])\n",
    "    #twitter_stream.filter(track=['*'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Understanding the data\n",
    "The data that we stored in tweets.json is in **JSON** format. JSON stands for *JavaScript Object Notation*. This format makes it easy to humans to read the data, and for machines to parse it. Below is an example for one tweet in JSON format. You can see that the tweet contains additional information in addition to the main text which in this example: \"*How #BigData and CRM are Shaping Modern Marketing https:\\/\\/t.co\\/TgUYSUp9jT https:\\/\\/t.co\\/V54kea8cT2*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"created_at\":\"Wed Oct 26 16:32:49 +0000 2016\",\"id\":791316663312457728,\"id_str\":\"791316663312457728\",\"text\":\"How #BigData and CRM are Shaping Modern Marketing https:\\/\\/t.co\\/TgUYSUp9jT https:\\/\\/t.co\\/V54kea8cT2\",\"display_text_range\":[0,73],\"source\":\"\\u003ca href=\\\"http:\\/\\/www.sociallymap.com\\\" rel=\\\"nofollow\\\"\\u003eSociallymap\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":4327758735,\"id_str\":\"4327758735\",\"name\":\"Globe Trotter BI\",\"screen_name\":\"GlobeTrotter_BI\",\"location\":null,\"url\":null,\"description\":\"* R\\u00e9seau international de consultants BI *      #Data #BusinessIntelligence #bigdata #datascientist #datamanagement\",\"protected\":false,\"verified\":false,\"followers_count\":104,\"friends_count\":212,\"listed_count\":50,\"favourites_count\":13,\"statuses_count\":318,\"created_at\":\"Mon Nov 30 10:15:23 +0000 2015\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":false,\"lang\":\"fr\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"C0DEED\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme1\\/bg.png\",\"profile_background_image_url_https\":....,\"favorited\":false,\"retweeted\":false,\"possibly_sensitive\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1477499569143\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the remaining of this lab, we will be using 4 Python libraries; *json* for parsing the data, *pandas* for data manipulation, *matplotlib* for creating charts, and *re* for regular expressions. \n",
    "\n",
    "The *json* and *re* libraries are installed by default in Python. You should install *pandas* and *matplotlib* if you don't have them in your machine.\n",
    "\n",
    "We will start first by uploading *json* and *pandas* using the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will read the data in into an array that we call tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "tweets_data_path = 'C:\\\\Program Files\\\\Anaconda2\\\\tweets_bigData_dataAnalytic.json'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "count = 0\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        count = count + 1\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "        if count%100 == 0:\n",
    "            sys.stdout.write('.')\n",
    "        if count%7000 == 0:\n",
    "            sys.stdout.write('\\n')\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        continue\n",
    "print \"\\n%s tweets read.\" % (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will structure the tweets data into a pandas *DataFrame* to simplify the data manipulation. We will start by creating an empty DataFrame called **tweets** using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add 3 columns to the **tweets** DataFrame called *text*, *lang*, and *country*, in which *text* column  contains the tweet, *lang* column contains the language in which the tweet was written, and *country* the country from which the tweet was sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['text'] = map(lambda tweet: tweet.get('text', None), tweets_data)\n",
    "tweets['lang'] = map(lambda tweet: tweet.get('lang', None), tweets_data)\n",
    "tweets['country'] = map(lambda tweet: tweet['place']['country'] if tweet.get('place') != None else None, tweets_data)\n",
    "print tweets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a chart describing the Top 15 countries from which the tweets were sent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "tweets_by_country = tweets['country'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='x', labelsize=10)\n",
    "ax.tick_params(axis='y', labelsize=10)\n",
    "ax.set_xlabel('Countries', fontsize=12)\n",
    "ax.set_ylabel('Number of tweets' , fontsize=12)\n",
    "ax.set_title('Top 15 countries', fontsize=12, fontweight='bold')\n",
    "tweets_by_country[:15].plot(ax=ax, kind='bar', color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **YOUR TURN**\n",
    "#### Problem01:\n",
    "Create a chart describing the Top 15 languages in which the tweets were written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "YOUR TURN NOW: \n",
    "1) create a chart describing the top 10 native languages of which \n",
    "the twitter users speak.\n",
    "2) create a chart describing ...\n",
    "''' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
