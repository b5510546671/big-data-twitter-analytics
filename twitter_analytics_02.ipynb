{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Twitter Data\n",
    "\n",
    "## Mining tweets\n",
    "Our main goal here is to compare the popularity of programming languages that have been used in **big data** and **data analytic**, and to retrieve the tutorial links of those programming languages. \n",
    "\n",
    "We will do this in 3 steps:\n",
    "\n",
    "* We will add tags to our tweets DataFrame in order to be able to manipualte the data easily.\n",
    "* Target tweets that have \"programming\" or \"tutorial\" keywords.\n",
    "* Extract links from the relevants tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Python, Java, R, MatLab, SAS, Scala, Unix tags\n",
    "First, we will create a function that checks if a specific keyword is present in a text. We will do this by using regular expressions. \n",
    "\n",
    "Using a Python library called \"**re**\", we will create a function called **word_in_text(word, text)**. This function will return *True* if a word is found in text, otherwise it returns *False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def word_in_text(word, text):\n",
    "    try:\n",
    "        word = word.lower()\n",
    "        text = text.lower()\n",
    "        match = re.search(word, text)\n",
    "        if match:\n",
    "            return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add these 7 columns to our tweets DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tweets_data_path = 'C:\\\\Program Files\\\\Anaconda2\\\\tweets_bigData_dataAnalytic.json'\n",
    "\n",
    "tweets_data = []\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "count = 0\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        count = count + 1\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "        if count%100 == 0:\n",
    "            sys.stdout.write('.')\n",
    "        if count%7000 == 0:\n",
    "            sys.stdout.write('\\n')\n",
    "    except Exception as e:\n",
    "        print e\n",
    "        continue\n",
    "print \"\\n%s tweets read.\" % (count)\n",
    "tweets = pd.DataFrame()\n",
    "tweets['text'] = map(lambda tweet: tweet.get('text', None), tweets_data)\n",
    "#print tweets.head(3)\n",
    "tweets['python'] = tweets['text'].apply(lambda tweet: word_in_text('python', tweet))\n",
    "tweets['java'] = tweets['text'].apply(lambda tweet: word_in_text('java', tweet))\n",
    "tweets['r'] = tweets['text'].apply(lambda tweet: word_in_text(' r pack', tweet))\n",
    "tweets['matlab'] = tweets['text'].apply(lambda tweet: word_in_text('matlab', tweet))\n",
    "tweets['sas'] = tweets['text'].apply(lambda tweet: word_in_text('sas', tweet))\n",
    "tweets['scala'] = tweets['text'].apply(lambda tweet: word_in_text('scala', tweet))\n",
    "tweets['unix'] = tweets['text'].apply(lambda tweet: word_in_text('unix', tweet))\n",
    "print tweets.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can calculate the number of tweets for those programming languages as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tweets['python'].value_counts()[1]\n",
    "print tweets['java'].value_counts()[1]\n",
    "print tweets['r'].value_counts()[1]\n",
    "print tweets['matlab'].value_counts()[1]\n",
    "print tweets['sas'].value_counts()[1]\n",
    "print tweets['scala'].value_counts()[1]\n",
    "print tweets['unix'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can make a simple comparaison chart by executing the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "keywords = ['python', 'java', 'r', 'matlab', 'sas', 'scala', 'unix']\n",
    "tweets_by_keywords = [tweets['python'].value_counts()[1], \\\n",
    "    tweets['java'].value_counts()[1], \\\n",
    "    tweets['r'].value_counts()[1], \\\n",
    "    tweets['matlab'].value_counts()[1], \\\n",
    "    tweets['sas'].value_counts()[1], \\\n",
    "    tweets['scala'].value_counts()[1], \\\n",
    "    tweets['unix'].value_counts()[1]]\n",
    "\n",
    "x_pos = list(range(len(keywords)))\n",
    "width = 0.6\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by_keywords, width, alpha=1, color='g')\n",
    "\n",
    "# Setting axis labels and ticks\n",
    "ax.set_ylabel('Number of tweets', fontsize=15)\n",
    "ax.set_title('Programming Languages used in Big Data Analytics',\\\n",
    "             fontsize=10, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(keywords)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeting relevant tweets\n",
    "We are intersted in targetting tweets that are related to any *tutorial* or *programming* stuff that concerns the big data or data scinece. We will then create an additional column to our tweets DataFrame where we will add this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets['tutorial'] = tweets['text'].apply(lambda tweet: word_in_text('tutorial', tweet))\n",
    "tweets[(tweets['python']==1) & (tweets['tutorial']==1)]\n",
    "s = tweets[(tweets['python']==1) & (tweets['tutorial']==1)]\n",
    "print len(s)\n",
    "#print s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To easy filter the records in out dataframe **tweets**, we can also add an additional column called \"*relevant*\" that take value 1 if the tweet has either \"Python\" and \"Tutorial\" keyword, otherwise it takes value 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['relevant'] = tweets['text'].apply(lambda tweet: word_in_text('python', tweet)\\\n",
    "    and word_in_text('tutorial', tweet))\n",
    "tweets[tweets['relevant']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, we can also add an additional column called \"*relevant*\" that take value 1 if the tweet has either \"Python\" and \"Programming\", or \"Java\" and \"Programming\", too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets['programming'] = tweets['text'].apply(lambda tweet:\\\n",
    "    (word_in_text('python', tweet) or word_in_text('java', tweet))\\\n",
    "    and word_in_text('programming', tweet))\n",
    "tweets[tweets['programming']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can count the number of tutorials, Python and Java programming courses, that have been found from the Twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tweets['tutorial'].value_counts()[1]\n",
    "print tweets[tweets['tutorial']==1]['python'].value_counts()[1]\n",
    "print\n",
    "print tweets['programming'].value_counts()[1]\n",
    "print tweets[tweets['programming']==1]['python'].value_counts()[1]\n",
    "print tweets[tweets['programming']==1]['java'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a comparison graph by executing the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_labels = ['Python Tutorial', 'Python Prog', 'Java Prog']\n",
    "tweets_by = [tweets[tweets['tutorial'] == 1]['python'].value_counts()[1],\\\n",
    "             tweets[tweets['programming'] == 1]['python'].value_counts()[1],\\\n",
    "             tweets[tweets['programming'] == 1]['java'].value_counts()[1]]\n",
    "x_pos = list(range(len(x_labels)))\n",
    "width = 0.8\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x_pos, tweets_by, width,alpha=1,color='g')\n",
    "ax.set_ylabel('Number of tweets', fontsize=12)\n",
    "ax.set_title('Number of found tutorials and programming courses.', fontsize=10, fontweight='bold')\n",
    "ax.set_xticks([p + 0.4 * width for p in x_pos])\n",
    "ax.set_xticklabels(x_labels)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, we can see that our tweets (i.e., users in twitters) talk about or offer many Java stuffs for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting links from relevant tweets\n",
    "Now, we will extract the relevant tweets, we want to retrieve links to any tutorials concerning big data and data science. We will start by creating a function that uses regular expressions for retrieving link that start with \"http://\" or \"https://\" from a text. This function will return the url if found, otherwise it returns an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_link(text):\n",
    "    regex = r'https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+'\n",
    "    match = re.search(regex, text)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will add a column called link to our tweets DataFrame. This column will contain the urls information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets['link'] = tweets['text'].apply(lambda tweet: extract_link(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a new DataFrame called **tweets_relevant_with_link**. This DataFrame is a subset of tweets DataFrame and contains all relevant tweets that have a link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_relevant = tweets[tweets['tutorial'] == 1]\n",
    "tweets_relevant_with_link = tweets_relevant[tweets_relevant['link'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out all links for Python tutorials by executing the commands below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tweets_relevant_with_link[tweets_relevant_with_link['python'] == 1]['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
