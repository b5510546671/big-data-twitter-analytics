{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Twitter Data\n",
    "## Tweets Processing with NLTK Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term co-occurrences\n",
    "Sometimes we are interested in the terms that occur together. This is mainly because the context gives us a better insight about the meaning of a term, supporting applications such as 'word disambiguation' or 'semantic similarity'. We discussed the option of using bigrams in the previous lab, but we want to extend the context of a term to the whole tweet.\n",
    "\n",
    "We can *refactor* the code from the previous lab in order to capture the co-occurrences. We build a co-occurrence matrix com such that com[x][y] contains the number of times the term x has been seen in the same tweet as the term y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "############################# from the old code of the previous lab\n",
    "# ;P\n",
    "############################# End old code here \n",
    "# new code begins here\n",
    "\n",
    "from collections import defaultdict\n",
    "com = defaultdict(lambda : defaultdict(int))\n",
    "# f is the file pointer to the JSON data set\n",
    "fname = \"tweets.json\"\n",
    "f = open(fname, 'r')\n",
    "for line in f: \n",
    "    tweet = json.loads(line)\n",
    "    # substitute, e.g. \\u2026, with space\n",
    "    tw = re.sub(r'[^\\x00-\\x7F]+',' ', tweet['text'])\n",
    "    terms_only = [term for term in preprocess(tw) \n",
    "                  if term not in stop \n",
    "                  and not term.startswith(('#', '@'))]\n",
    " \n",
    "    # Build co-occurrence matrix\n",
    "    for i in range(len(terms_only)-1):            \n",
    "        for j in range(i+1, len(terms_only)):\n",
    "            w1, w2 = sorted([terms_only[i], terms_only[j]])                \n",
    "            if w1 != w2:\n",
    "                com[w1][w2] += 1\n",
    "print \"Done..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While building the co-occurrence matrix, we donâ€™t want to count the same term pair twice, e.g. com[A][B] == com[B][A], so the inner for loop starts from i+1 in order to build a triangular matrix, while sorted will preserve the alphabetical order of the terms.\n",
    "\n",
    "For each term, we then extract the 10 most frequent co-occurrent terms, creating a list of tuples in the form ((term1, term2), count):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "com_max = []\n",
    "# For each term, look for the most common co-occurrent terms\n",
    "for t1 in com:\n",
    "    t1_max_terms = sorted(com[t1].items(), key=operator.itemgetter(1),\\\n",
    "        reverse=True)[:10]\n",
    "    for t2, t2_count in t1_max_terms:\n",
    "        com_max.append(((t1, t2), t2_count))\n",
    "# Get the most frequent co-occurrences\n",
    "terms_max = sorted(com_max, key=operator.itemgetter(1), reverse=True)\n",
    "print(terms_max[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also look for a specific term and extract its most frequent co-occurrences. We simply need to modify the main loop including an extra counter, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "search_word = raw_input('Enter your query: ') # input a term query\n",
    "count_search = Counter()\n",
    "\n",
    "fname = \"c:\\\\Program Files\\\\Anaconda2\\\\tweets_bigData_dataAnalytic.json\"\n",
    "f = open(fname, 'r')\n",
    "\n",
    "count = 0\n",
    "for line in f:\n",
    "    count = count + 1\n",
    "    if count%500 == 0:\n",
    "        sys.stdout.write('.')\n",
    "    if count%35000 == 0:\n",
    "        sys.stdout.write('\\n')\n",
    "    tweet = json.loads(line)\n",
    "    # substitute, e.g. \\u2026, with space\n",
    "    tw = re.sub(r'[^\\x00-\\x7F]+',' ', tweet['text'])\n",
    "    terms_only = [term for term in preprocess(tw)\\\n",
    "        if term not in stop and not term.startswith(('#', '@'))]\n",
    "    if search_word in terms_only:\n",
    "        count_search.update(terms_only)\n",
    "print(\"\\nCo-occurrence for %s:\" % search_word)\n",
    "print(count_search.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}